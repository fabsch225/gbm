\section{Stochastische Analysis und alternative Kursmodelle}

Dieses Kapitel soll einen Einblick in weiterführende mathematische Aspekte geben, die in dieser Arbeit nicht vertieft wurden.
Es ersetzt somit den obligatorischen Abschnitt \"Ausblick\" in einer Bachelorarbeit.

\paragraph{Motivation Stochastischer Differentialgleichungen}

Im Kapitel 5 wurde ein Aktienkurs durch die zeitdiskrete Übergangsgleichung
$$S_{n+1} = S_n \big(1 + \mu \Delta t + \sigma \sqrt{\Delta t}\,\varepsilon_{n+1}\big)$$
modelliert. Ziel des folgenden Abschnitts ist es, den Grenzübergang $\Delta t \to 0$ zu betrachten,
um eine kontinuierliche Beschreibung der Kursdynamik zu erhalten. Dabei soll die stochastische Differentialgleichung
$$dS_t = \mu S_t\,dt + \sigma S_t\,dW_t$$
hergeleitet werden, deren Lösung die geometrische Brownsche Bewegung ist. 
Anschaulich muss man sich nur noch von $\sqrt{\Delta t} \varepsilon_{n+1} \to dW_t$ überzeugen, wobei $W_t$ eine Brownsche Bewegung ist.
Sei $\Delta t = T/n$ und $(\varepsilon_k)_{k\ge 1}$ i.i.d. mit $\mathbb E[\varepsilon_k]=0$, $\mathbb Var(\varepsilon_k)=1$.
Definiere den skalierten Zufallsspaziergang
$$
W^{(n)}(t) := \sqrt{\Delta t}\sum_{k=1}^{\lfloor t/\Delta t\rfloor}\varepsilon_k,\qquad t\in[0,T].
$$
Dann gilt für jedes feste $t$ nach dem Zentralen Grenzwertsatz (ZGWS)
$$
W^{(n)}(t)\ \to\ \mathcal N(0,t).
$$
Und nach Kapitel 4 konvergiert $W^{(n)}$ sogar gegen eine Brownsche Bewegung $W$.

Insbesondere sind die diskreten Inkremente unabhängig und es gilt für $k=\lfloor t/\Delta t\rfloor$
$$
W^{(n)}(t+\Delta t)-W^{(n)}(t)\;=\;\sqrt{\Delta t}\,\varepsilon_{k+1}\ \sim\ \mathcal N(0,\Delta t).
$$
Mit $W^{(n)}\to W$ folgt damit für jedes $t$ die Verteilungskonvergenz der Inkremente
$$
\sqrt{\Delta t}\,\varepsilon_{k+1}
\;=\;W^{(n)}(t+\Delta t)-W^{(n)}(t)\ \to \ W_{t+\Delta t}-W_t,
$$
Durch Missbrauch der Notation erhält man
$$
\sqrt{\Delta t}\,\varepsilon_{n+1}\ \to\ dW_t.
$$
Insgesamt gilt
$$\Delta t \to dt, \qquad S_{t + \Delta t} - S_t \to dS_t$$
und $\sqrt{\Delta t} \varepsilon_{n+1} \to dW_t$
kann die Übergangsgleichung als stochastische Differentialgleichung interpretiert werden.
\qed

Formal werden stochastische Differentialgleichungen über das It\^o-Integral eingeführt, das wird 
im nächsten Abschnitt skizziert, für eine genaue Darstellung sei auf die Literatur verwiesen, z. B. Behrends \cite{behrends} oder Karatzas und Shreve \cite{karatzas_brownian_1991}.
Die Argumentation ist analog zu Kapitel 6 des Lehrbuchs von Behrends \cite{behrends}.

\subsection{Stochastische Differentialgleichungen}
TODO: weniger Lehrbuchmäßig formulieren, mehr auf Intuition und Zusammenhang mit dem bisherigen Text eingehen.
Ziel dieses Abschnitts ist es, die heuristische Schreibweise
$$
dS_t \;=\; a(S_t,t)\,dt \;+\; b(S_t,t)\,dW_t
$$
zu präzisieren: Man definiert das Integral gegen Brownsche Bewegung zunächst für \emph{elementare} (stückweise konstante, vorhersagbare) Prozesse, zeigt die It\^o-Isometrie, benutzt die Dichtheit dieser elementaren Prozesse und erhält so das It\^o-Integral für allgemeine quadratintegrierbare, vorhersagbare Integranden.

\paragraph{Grundaufbau}
Arbeitsraum ist ein filtrierter Wahrscheinlichkeitsraum
$$
(\Omega,\mathcal F,(\mathcal F_t)_{t\ge 0},\mathbb P).
$$
Eine Standard-\emph{Brownsche Bewegung} $W=(W_t)_{t\ge 0}$ ist ein $(\mathcal F_t)$-adaptierter Prozess mit $W_0=0$, stetigen Pfaden, unabhängigen Zuwächsen und
$$
W_t - W_s \sim \mathcal N(0,t-s)\quad\text{für }0\le s<t.
$$
Ein Prozess $X=(X_t)_{t\ge 0}$ heißt \emph{adaptiert}, falls er bezüglich der vorhersagbaren $\sigma$-Algebra messbar ist; für die Konstruktion genügt es, zuerst stückweise konstante, adaptierte Prozesse zu betrachten.

\paragraph{Elementare (adaptierte) Prozesse und ihr Integral}
Fixiere $T>0$. Ein Prozess $H$ heißt \emph{elementar adaptiert} auf $[0,T]$, wenn es eine Zerlegung $0=t_0<t_1<\dots<t_n=T$ und Zufallsvariablen $\xi_i\in L^2(\Omega,\mathcal F_{t_i},\mathbb P)$, $i=0,\dots,n-1$, gibt mit
$$
H_t \;=\; \sum_{i=0}^{n-1} \xi_i\,\mathbf 1_{(t_i,t_{i+1}]}(t),\qquad t\in[0,T].
$$
Für solche $H$ definiert das \emph{It\^o-Integral} gegen $W$ durch
$$
\int_0^T H_s\,dW_s \;:=\; \sum_{i=0}^{n-1} \xi_i\,\big(W_{t_{i+1}}-W_{t_i}\big).
$$
Zentrale Eigenschaften (für $H$ wie oben):
$$
\mathbb E\!\left[\int_0^T H_s\,dW_s\right] \;=\; 0,\qquad
\mathbb E\!\left[\Big(\int_0^T H_s\,dW_s\Big)^{\!2}\right] \;=\; \mathbb E\!\left[\int_0^T H_s^2\,ds\right]
$$
(dies ist die \emph{It\^o-Isometrie}). Für die zeitabhängige Version definiert man für $t\in[0,T]$
$$
\int_0^t H_s\,dW_s \;:=\; \sum_{i=0}^{n-1} \xi_i\,\big(W_{t\wedge t_{i+1}}-W_{t\wedge t_i}\big),
$$
und erhält einen $(\mathcal F_t)$-Martingalprozess mit Quadratischer Variation
$[\!\int_0^\cdot H_s dW_s]_t = \int_0^t H_s^2\,ds$.

\paragraph{Dichtheit der elementaren Prozesse}
Sei $L^2_{\mathrm{pred}}(\Omega\times[0,T])$ der Raum aller vorhersagbaren Prozesse $X$ mit
$\|X\|_{2,T}^2 := \mathbb E\!\int_0^T |X_s|^2 ds <\infty$.
Dann ist die Klasse der elementaren vorhersagbaren Prozesse dicht in $L^2_{\mathrm{pred}}(\Omega\times[0,T])$ bezüglich der Norm $\|\cdot\|_{2,T}$. (Siehe z. B. Karatzas und Shreve \cite{karatzas_brownian_1991}, S. 132f.)
\paragraph{Definition des It\^o-Integrals}
Für einen allgemeinen vorhersagbaren Prozess $X\in L^2_{\mathrm{pred}}(\Omega\times[0,T])$ wähle eine Folge elementarer Prozesse $H^{(n)}$ mit
$\|H^{(n)}-X\|_{2,T}\to 0$. Dann definieren wir
$$
\int_0^T X_s\,dW_s \;:=\; L^2\text{-}\lim_{n\to\infty}\;\int_0^T H^{(n)}_s\,dW_s,
$$
wobei der Limes aufgrund der It\^o-Isometrie existiert und nicht von der approximierenden Folge abhängt. Für jedes $t\in[0,T]$ definiert man analog den Prozess
$$
\Big(\int_0^t X_s\,dW_s\Big)_{t\in[0,T]},
$$
und es gilt weiterhin die It\^o-Isometrie
$$
\mathbb E\!\left[\Big(\int_0^T X_s\,dW_s\Big)^{\!2}\right] \;=\; \mathbb E\!\left[\int_0^T X_s^{2}\,ds\right],
$$
sowie die Martingaleigenschaft von $M_t:=\int_0^t X_s\,dW_s$. Für lokal quadratintegrierbare $X$ erhält man das Integral durch Lokalisierung via Stoppzeiten.

\paragraph{Verbindung zur heuristischen Notation}
Mit dieser Konstruktion ist die Schreibweise
$$
dS_t \;=\; a(S_t,t)\,dt \;+\; b(S_t,t)\,dW_t
$$
präzise zu lesen als Integralgleichung
$$
S_t \;=\; S_0 \;+\; \int_0^t a(S_s,s)\,ds \;+\; \int_0^t b(S_s,s)\,dW_s,
$$
wobei $b(S_\cdot,\cdot)$ vorhersagbar und quadratintegrierbar sein muss.


\subsection{Charakterisierung alternativer Kursmodelle durch stochastische Differentialgleichungen}

Die GBM nimmt konstante Volatilität und lognormale Renditen an; sie erzeugt weder Sprünge noch Volatilitäts-Clustering oder kann Konjunkturperioden Modellieren.
Glasserman \cite{glasserman2003monte} beschreibt verschiedene Ansätze zur Modellierung dieser Phänomene:

\paragraph{Lokale Volatilität}
Deterministisch zeit- und zustandsabhängige Volatilität:
$$
dS_t \;=\; \mu(t,S_t)\,S_t\,dt \;+\; \sigma_{\mathrm{loc}}(t,S_t)\,S_t\,dW_t.
$$
Spezialfall CEV:
$$
dS_t \;=\; \mu S_t\,dt \;+\; \sigma\,S_t^{\beta}\,dW_t,\qquad \beta\in\mathbb R,
$$
wodurch die Volatilität bei kleinen/größeren Preisen relativ ansteigt/abnimmt.

\paragraph{Stochastische Volatilität}
Volatilität ist selbst ein Zufallsprozess.
$$
\begin{aligned}
dS_t &= \mu S_t\,dt + \sqrt{V_t}\,S_t\,dW_t^{(1)},\\
dV_t &= \kappa(\theta - V_t)\,dt + \xi\sqrt{V_t}\,dW_t^{(2)},\quad d \langle W^{(1)},W^{(2)}\rangle_t=\rho\,dt,
\end{aligned}
$$
mit Feller-Bedingung $2\kappa\theta\ge \xi^2$ für Positivität von $V_t$.

\paragraph{Sprung-Diffusions-Modelle}
Diffusion mit seltenen Sprüngen modelliert durch Poisson-Prozesse.
$$
\frac{dS_t}{S_t} \;=\; \big(\mu - \lambda \kappa_J\big)\,dt \;+\; \sigma\,dW_t \;+\; (J_t-1)\,dN_t,
$$
wobei $N_t$ Poisson mit Intensität $\lambda$ ist, $J_t$ die Sprunggröße (z.\,B. lognormal) und $\kappa_J=\mathbb E[J_t-1]$; der Driftterm kompensiert die Sprünge.

\paragraph{Regimewechsel-Modelle}
Parameter schalten gemäß einer (verborgenen) Markov-Kette $X_t$:
$$
dS_t \;=\; \mu_{X_t} S_t\,dt \;+\; \sigma_{X_t} S_t\,dW_t.
$$
Erfasst Phasen wie Krisen und ruhige Märkte.

\subsection{Simulation stochastischer Differentialgleichungen}
Zu einer SDE
$$
dX_t \;=\; a(X_t,t)\,dt \;+\; b(X_t,t)\,dW_t,\quad t\in[0,T],
$$
wird ein Zeitschrittgitter $t_n=n\Delta t$ eingeführt und der kontinuierliche Prozess durch eine zeitdiskrete Approximation ersetzt. Erwartungswerte werden via Monte‑Carlo über viele simulierte Pfade geschätzt. Der Gesamtfehler setzt sich aus Diskretisierungsfehler (Bias) und Monte‑Carlo‑Fehler $O(M^{-1/2})$ zusammen.

Die Differentialgleichung wird mit Euler (deterministisch) und Euler–Maruyama (stochastisch) diskretisiert (vgl. Bärwolff \cite{Baerwolff2025} u. a. S. 269, 466f.).
Für die ODE $\dot x(t)=a(x(t),t)$ liefert das explizite Euler‑Schema
$$
x_{n+1} \;=\; x_n \;+\; a(x_n,t_n)\,\Delta t.
$$
Ersetzt man nun formal $dW_t$ durch $\Delta W_n:=W_{t_{n+1}}-W_{t_n}\sim \mathcal N(0,\Delta t)$, erhält man die natürliche stochastische Erweiterung, das Euler–Maruyama‑Schema:
$$
X_{n+1} \;=\; X_n \;+\; a(X_n,t_n)\,\Delta t \;+\; b(X_n,t_n)\,\Delta W_n
\;=\; X_n \;+\; a(X_n,t_n)\,\Delta t \;+\; b(X_n,t_n)\,\sqrt{\Delta t}\,\varepsilon_{n+1},
$$
mit i.i.d. $\varepsilon_{n}\sim\mathcal N(0,1)$. 
Ähnlich wurde im Hauptteil die geometrische Brownsche Bewegung hergeleitet.
Es folgt ein R-Programm zur Simulation eines CEV-Modells (s. u.).

\begin{lstlisting}
simulate_cev_paths <- function(S0, mu, sigma, beta, dt, nsteps, npaths) {
  S <- matrix(NA, nrow = nsteps + 1, ncol = npaths)
  S[1, ] <- S0
  for (i in 1:nsteps) {
    Z <- rnorm(npaths)
    S[i+1, ] <- S[i, ] + mu * S[i, ] * dt + sigma * (S[i, ]^beta) * sqrt(dt) * Z
    S[i+1, ][S[i+1, ] <= 0] <- 1e-8
  }
  return(S)
}
\end{lstlisting}

\subsection{Fallstudie: CEV (Constant Elasticity of Variance) Modell}
Das CEV-Modell ist ein Spezialfall der lokalen Volatilität mit
$$
dS_t \;=\; \mu\,S_t\,dt \;+\; \sigma\,S_t^{\beta}\,dW_t,\qquad \beta\in\mathbb R.
$$
\begin{itemize}
\item $\beta=1$ ergibt GBM. 
\item $\beta<1$ erhöht die relative Volatilität bei kleinen Preisen (dickere linke Schwänze).
\item $\beta>1$ verstärkt Schwankungen bei hohen Preisen.
\end{itemize}
Mit diskreten Beobachtungen $S_{t_i}$ im Abstand $\Delta t$ liefert das Euler‑Schema
$$
\Delta S_i \approx \mu S_{t_i}\Delta t + \sigma S_{t_i}^{\beta}\sqrt{\Delta t}\,\varepsilon_i,\quad \varepsilon_i\sim\mathcal N(0,1).
$$
Die nächste Herausforderung ist die Kalibrierung (Parameterschätzung) aus gegebenen Daten. Die Arbeit 
orientiert sich im folgenden an Iacus (2008, S. 122 ff.) \cite{iacus2008}. Eine eigene Implementierung in
R wird danach mit dem Softwarepaket Sim.DiffProc. \cite{rsde} (2020) verglichen, das man auf den selben Ansatz konfigurieren kann.
Der Ansatz ist die numerische Maximierung einer Log-Likelihood-Funktion, die im Folgenden für die diskrete Übergangswahrscheinlichkeit hergeleitet wird.
Das wird durch die Approximation der Übergangsdichte (eine bedingte Dichte) mittels des Euler-Maruyama-Schemas erreicht. Da sich für $\beta=1$ eine klassische geometrische Brownsche Bewegung ergibt, 
können die bekannten Schätzer für Drift und Volatilität als Spezialfall betrachtet werden. Insbesondere stellen die Parameter der GBM 
sinnvolle Startwerte für die numerische Optimierung dar.


\paragraph{Exkurs: (Quasi) Maximum-Likelihood-Schätzung (MLE, QMLE)}
Ziel ist die Parameterschätzung aus diskreten Beobachtungen $S_{t_0},\dots,S_{t_n}$ eines SDE
$dS_t=a(S_t,t)\,dt+b(S_t,t)\,dW_t$. Grundidee: Wähle Parameter $\theta$ so, dass die beobachteten Daten unter dem Modell am wahrscheinlichsten sind. Für diskrete Beobachtungen $S_{t_0},\dots,S_{t_n}$ eines (Markov‑)Modells gilt
$$
L(\theta) \;=\; \prod_{i=0}^{n-1} p_\theta\!\big(S_{t_{i+1}},\,\Delta t \,\big|\, S_{t_i}\big), 
\qquad
\ell(\theta)=\log L(\theta)=\sum_{i=0}^{n-1}\log p_\theta\!\big(S_{t_{i+1}},\Delta t \,\big|\, S_{t_i}\big),
$$
wobei $p_\theta(\,\cdot\,|\,\cdot)$ die bedingte Übergangsdichte in Schrittweite $\Delta t$ ist. Der MLE ist
$$
\widehat\theta\;=\;\arg\max_{\theta}\ \ell(\theta).
$$
Da $p_\theta$ nicht explizit bekannt ist, wird eine Quasi-Likelihood (QMLE) verwendet, hier die Euler-Maruyama-Approximation.
$$
S_{t_{i+1}}-S_{t_i}\mid S_{t_i}\ \approx\ \mathcal N\!\big(a_\theta(S_{t_i},t_i)\,\Delta t,\; b_\theta^2(S_{t_i},t_i)\,\Delta t\big),
$$
Dann wird die (Pseudo‑)Log‑Likelihood aufgestellt, und numerisch maximiert.

\paragraph{Herleitung des Quasi‑MLE (Euler‑Pseudo‑Likelihood).}
Das CEV-Modell lautet
$$
dS_t = \mu S_t\,dt + \sigma S_t^{\beta}\,dW_t.
$$
Für kleine Zeitschritte $\Delta t$ wird die Differentialgleichung diskretisiert:
$$
S_{t_{i+1}} \approx S_{t_i} + \mu S_{t_i} \Delta t + \sigma S_{t_i}^{\beta} \sqrt{\Delta t}\, \varepsilon_{i+1},
$$
wobei $\varepsilon_{i+1} \sim \mathcal N(0,1)$ unabhängig sind.
Definiere die Inkremente:
$$
\Delta S_i := S_{t_{i+1}} - S_{t_i}
$$
Nach obiger Diskretisierung gilt näherungsweise (in die man die deterministischen Terme in die Verteilung von $\varepsilon$ reinzieht):
$$
\Delta S_i \mid S_{t_i} \sim \mathcal N\left(\mu S_{t_i} \Delta t,\, \sigma^2 S_{t_i}^{2\beta} \Delta t\right)
$$
Das heißt: Für gegebenen Kurs $S_{t_i}$ ist der nächste Schritt normalverteilt mit Mittelwert $\mu S_{t_i} \Delta t$ und Varianz $\sigma^2 S_{t_i}^{2\beta} \Delta t$.
Die Dichte einer Normalverteilung mit Mittelwert $m$ und Varianz $v$ an der Stelle $x$ ist:
$$
p(x) = \frac{1}{\sqrt{2\pi v}} \exp\left(-\frac{(x-m)^2}{2v}\right)
$$
Setze $m = \mu S_{t_i} \Delta t$, $v = \sigma^2 S_{t_i}^{2\beta} \Delta t$, $x = \Delta S_i$.
Die gemeinsame Likelihood für alle Schritte ist das Produkt der Einzeldichten:
$$
L(\mu, \sigma, \beta) = \prod_{i=0}^{n-1} p(\Delta S_i \mid S_{t_i})
$$
Da Produkte numerisch unhandlich sind, nimmt man den Logarithmus:
$$
\ell(\mu, \sigma, \beta) = \sum_{i=0}^{n-1} \log p(\Delta S_i \mid S_{t_i})
$$
Setzt die Dichte ergibt sich der Likelihood-Ausdruck:
\begin{align*}
\ell(\mu, \sigma, \beta) &= \sum_{i=0}^{n-1} \left[
    -\frac{1}{2} \log(2\pi \sigma^2 S_{t_i}^{2\beta} \Delta t)
    -\frac{(\Delta S_i - \mu S_{t_i} \Delta t)^2}{2 \sigma^2 S_{t_i}^{2\beta} \Delta t}
\right] \\
&= -\frac{1}{2} \sum_{i=0}^{n-1} \left[
    \log(2\pi \sigma^2 S_{t_i}^{2\beta} \Delta t)
    + \frac{(\Delta S_i - \mu S_{t_i} \Delta t)^2}{\sigma^2 S_{t_i}^{2\beta} \Delta t}
\right]
\end{align*}
\textit{Interpretation.} Die Log-Likelihood misst, wie gut die Parameter $(\mu, \sigma, \beta)$ die beobachteten Kursänderungen erklären. Der erste Term bestraft große Varianzen, der zweite Term misst die Abweichung der beobachteten Inkremente von den erwarteten Werten.
Die Schätzungen der Parameter erhält man durch Maximierung der Log-Likelihood:
$$
(\widehat{\mu}, \widehat{\sigma}, \widehat{\beta}) = \arg\max_{\mu, \sigma, \beta} \; \ell(\mu, \sigma, \beta)
$$
Da die Funktion keine einfache analytische Lösung hat, wird sie mit numerischen Optimierungsverfahren (z.B. L-BFGS-B) maximiert.

\paragraph{Implementierung in R mit dem Paket Sim Diffproc}
Die Parameterschätzung für das CEV-Modell kann mit dem R-Paket Sim.DiffProc durchgeführt werden. Die Funktion \texttt{fitsde} erlaubt die Schätzung der Drift- und Diffusionsparameter mittels Pseudo-Maximum-Likelihood auf Basis diskreter Zeitreihen. Das folgende R-Programm (Ausschnitt) zeigt die Anwendung auf DAX-Daten.
Die Optimierung erfolgt mit dem Algorithmus L-BFGS-B und die Parametergrenzen sind gesetzt, um numerische Probleme zu vermeiden.

\begin{lstlisting}
S_ts <- ts(dax$Price, deltat = dt_daily)

drift     <- expression(theta[1] * x)           # theta1 = mu
diffusion <- expression(theta[2] * x^theta[3])    # theta2 = sigma, theta3 = beta

fit_cev <- fitsde(
  data      = S_ts,
  drift     = drift,
  diffusion = diffusion,
  start     = start_vals,
  pmle      = "euler",
  optim.method = "L-BFGS-B",
  lower     = c(mu = -Inf, sigma = 1e-8, beta = 0.0),
  upper     = c(mu =  Inf, sigma =  Inf, beta = 3.0)
)
\end{lstlisting}

Es folgt ein Backtest mit den geschätzten Parametern (vgl. Kapitel 7). Hier werden 1000 Pfade mit der
Euler-Maruyama-Methode simuliert, und dann die empirischen 75\%-Quantile genommen.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/cev_dax_backtest.png}
    \caption{Backtest CEV-Modell für den DAX}
    \label{fig:cev_dax_backtest}
\end{figure}

Die Überdeckungswahrscheinlichkeit liegt bei 82\%. Dieselbe Konfiguration
lieferte für die gemetrische Brownsche Bewegung eine Überdeckungswahrscheinlichkeit von 86\% (größer ist besser).
Ein feinerer Vergleich der Kalibrierungen folgt im nächsten Abschnitt. 

\paragraph{Eigene Implementierung in R mit der Euler‑Pseudo‑Likelihood}
Die eigene Implementierung der Parameterschätzung für das CEV-Modell in R basiert auf der oben hergeleiteten Pseudo-Maximum-Likelihood-Funktion.
Zur numerischen Optimierung wird das Paket nloptr \cite{nlopt} verwendet.

\begin{lstlisting}
estimate_cev <- function(S, dt = 1/252) {
  S <- as.numeric(S)
  stopifnot(is.numeric(S), all(is.finite(S)), length(S) >= 3)
  
  dS  <- diff(S)
  S0  <- S[-length(S)]
  eps <- 1e-12
  S0[S0 <= 0] <- eps
  sigma_start <- sd(dax_in$logret)  / sqrt(dt_daily)
  mu_start    <- mean(dax_in$logret) / dt_daily - sigma_start / 2
  beta_start  <- 1.0
  init <- c(mu_start, sigma_start, beta_start) 
  
  negloglik <- function(par) {
    mu    <- par[1]
    sigma <- par[2]
    beta  <- par[3]
    if (!is.finite(mu) || !is.finite(sigma) || !is.finite(beta)) return(1e12)
    if (sigma <= 0 || beta <= 0 || beta >= 5) return(1e12)
    
    denom <- (sigma*sigma) * (S0^(2*beta)) * dt
    denom[denom <= 0] <- eps
    val <- 0.5 * sum(log(2*pi*denom) + ((dS - mu*S0*dt)^2)/denom)
    if (!is.finite(val)) val <- 1e12
    as.numeric(val)
  }
  
  res <- nloptr(
    x0     = init,
    eval_f = negloglik,
    lb     = c(-Inf, 1e-8, 1e-6),
    ub     = c( Inf,  Inf,  4.999),
    opts   = list(algorithm = "NLOPT_LN_SBPLX", xtol_rel = 1e-8, maxeval = 3000)
  )
  
  list(mu = res$solution[1], sigma = res$solution[2], beta = res$solution[3])
}
\end{lstlisting}

\paragraph{Vergleich der Kalibrierungen}
Im Vergleich des Standardpakets mit der eigenen Implementierung zeigt sich, dass die geschätzten Parameter bloß geringe Unterschiede aufweisen.
Das liegt vermutlich an den unterschiedlichen (numerischen) Optimierungsalgorithmen und anderen Implementierungsdetails. Man kann jedoch
schließen, dass die Schätzung korrekt implementiert ist.

\begin{table}[H]
\centering
\caption{Vergleich der geschätzten Parameter ($\mu$, $\sigma$, $\beta$) für die beiden Schätzprogramme}
\label{tab:compare_models_ab}
\begin{tabular}{lcccccc}
\hline
 & \multicolumn{3}{c}{Eigene Implementierung} & \multicolumn{3}{c}{Paket} \\
\cline{2-4}\cline{5-7}
Kurs & $\mu$ & $\sigma$ & $\beta$ & $\mu$ & $\sigma$ & $\beta$ \\
\hline
DAX & $0.0946$ & $0.6545$ & $0.8726$ & $0.0950$ & $0.6524$ & $0.873$ \\
Lufthansa & $0.003$ & $0.8483$ & $0.6423$ & $0.0035$ & $0.8484$ & $0.6423$ \\
Adesso & $0.2686$ & $0.4114$ & $1.0031$ & $0.2686$ & $0.4122$ & $1.0026$ \\
\hline
\end{tabular}
\end{table}

\subsection{Ergebnisse und Vergleich der Modelle}

Nun wird das CEV-Modell (mit der Kalibrierung aus Sim.Diffproc) mit der geometrischen Brownschen Bewegung (GBM) verglichen. Die beiden Modelle werden auf die gleichen Daten angewendet, und dann ein Backtest durchgeführt, um die Leistung der Modelle zu bewerten.
Der Backtest wird mit verschiedenen Aufteilungen durchgeführt um die Robustheit der Ergebnisse zu versichern.
Man kann bei den Ergebnissen der Backtests feststellen, dass das CEV-Modell bei große Datenmengen (hohe Weights) eine bessere Leistung zeigt als die GBM, dagegen ist bei niedrigen Datenmengen
die GBM überlegen, da das Modell simpler und daher weniger anfällig für Überanpassung ist.

\begin{sidewaystable}
\centering
\csvautotabular{../r/out_compare.csv}
\caption{Vergleich der Modelle GBM und CEV über verschiedene Backtests und Metriken: Hitratio - größer ist besser; RMSE - kleiner ist besser; MAPE - kleiner ist besser; NRMSE - kleiner ist besser}
\end{sidewaystable}
